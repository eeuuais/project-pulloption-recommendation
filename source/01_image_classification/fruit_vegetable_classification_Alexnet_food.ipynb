{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"fruit&vegetable_classification_Alexnet_food.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMWolH+FCO8EW6ZjQgyUGvr"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"cneyKQ7-8edu"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","import PIL\n","import tensorflow as tf\n","\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from tensorflow.keras.models import Sequential\n","\n","from tensorflow.keras import Model\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.losses import categorical_crossentropy\n","from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n"]},{"cell_type":"code","source":["import pathlib\n","data_dir = pathlib.Path('C:/Users/HERO/Desktop/Graduate school/1학기\\\n","/텐서플로우 활용기초/팀프로젝트/food detection/Fruit_vegetable')\n"],"metadata":{"id":"txYfM4rO8zK9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["batch_size = 32\n","img_height = 180\n","img_width = 180"],"metadata":{"id":"WjegXREf8zNP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n","  data_dir,\n","  validation_split=0.2,\n","  subset=\"training\",\n","  seed=123,\n","  image_size=(img_height, img_width),\n","  batch_size=batch_size)\n"],"metadata":{"id":"9y9MAHXx8zPa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n","  data_dir,\n","  validation_split=0.2,\n","  subset=\"validation\",\n","  seed=123,\n","  image_size=(img_height, img_width),\n","  batch_size=batch_size)"],"metadata":{"id":"x8W6MLN78zRh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class_names = train_ds.class_names\n","print(class_names)"],"metadata":{"id":"L39_C0pK8zTd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","plt.figure(figsize=(10, 10))\n","for images, labels in train_ds.take(1):\n","    for i in range(9):\n","        ax = plt.subplot(3, 3, i + 1)\n","        plt.imshow(images[i].numpy().astype(\"uint8\"))\n","        plt.title(class_names[labels[i]])\n","        plt.axis(\"off\")"],"metadata":{"id":"R5brkRTC8zVn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for image_batch, labels_batch in train_ds:\n","    print(image_batch.shape)\n","    print(labels_batch.shape)\n","    break"],"metadata":{"id":"3eLxPbDR8zYc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["AUTOTUNE = tf.data.experimental.AUTOTUNE\n","\n","train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n","val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"],"metadata":{"id":"aEwkr9lR8zaj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["num_classes=50\n","input_shape=(180,180,3)\n","model_Alexnet = Sequential([\n","  layers.experimental.preprocessing.Rescaling(1./255),\n","  layers.Conv2D(96, kernel_size=(11,11), strides=4,\n","                        padding='valid', activation='relu',\n","                        input_shape=input_shape,\n","                       kernel_initializer='he_normal'),\n","  layers.MaxPooling2D(pool_size=(3,3), strides=(2,2),\n","                             padding='valid', data_format='channels_last'),\n","  layers.Conv2D(256, kernel_size=(5,5), strides=1,\n","                       padding='same', activation='relu',\n","                       kernel_initializer='he_normal'),\n","  layers.MaxPooling2D(pool_size=(3,3), strides=(2,2),\n","                             padding='valid', data_format='channels_last'),\n","  layers.Conv2D(384, kernel_size=(3,3), strides=1,\n","                       padding='same', activation='relu',\n","                       kernel_initializer='he_normal'),\n","  layers.Conv2D(384, kernel_size=(3,3), strides=1,\n","                       padding='same', activation='relu',\n","                       kernel_initializer='he_normal'),\n","  layers.Conv2D(256, kernel_size=(3,3), strides=1,\n","                       padding='same', activation='relu',\n","                       kernel_initializer='he_normal'),\n","  layers.MaxPooling2D(pool_size=(3,3), strides=(2,2),\n","                             padding='valid', data_format='channels_last'),\n","  layers.Flatten(),\n","  layers.Dense(4096, activation='relu'),\n","  layers.Dense(4096, activation='relu'),\n","  layers.Dense(1000, activation='relu'),\n","  layers.Dense(num_classes, activation='softmax'),\n","])\n","        "],"metadata":{"id":"H9ZvYXaW8zc-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_Alexnet.compile(optimizer='adam',\n","              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","              metrics=['accuracy'])"],"metadata":{"id":"9Bdqc_2J8zgm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_Alexnet.summary()"],"metadata":{"id":"Np0fUT2C8zi2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["epochs = 20\n","history = model_Alexnet.fit(\n","  train_ds,\n","  validation_data=val_ds,\n","  epochs=epochs\n",")"],"metadata":{"id":"AtjDhCW38zks"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["acc = history.history['accuracy']\n","val_acc = history.history['val_accuracy']\n","\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","\n","epochs_range = range(epochs)\n","\n","plt.figure(figsize=(8, 8))\n","plt.subplot(1, 2, 1)\n","plt.plot(epochs_range, acc, label='Training Accuracy')\n","plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n","plt.legend(loc='lower right')\n","plt.title('Training and Validation Accuracy')\n","\n","plt.subplot(1, 2, 2)\n","plt.plot(epochs_range, loss, label='Training Loss')\n","plt.plot(epochs_range, val_loss, label='Validation Loss')\n","plt.legend(loc='upper right')\n","plt.title('Training and Validation Loss')\n","plt.show()"],"metadata":{"id":"O_RiKvlo9C0v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["image_path ='C:/Users/HERO/Desktop/Graduate school/1학기\\\n","/텐서플로우 활용기초/팀프로젝트/food detection/prediction/Predict_image1.jpg'\n","\n","img = keras.preprocessing.image.load_img(\n","    image_path, target_size=(img_height, img_width)\n",")\n","img_array = keras.preprocessing.image.img_to_array(img)\n","img_array = tf.expand_dims(img_array, 0) # Create a batch\n","\n","predictions = model_Alexnet.predict(img_array)\n","score = tf.nn.softmax(predictions[0])\n","\n","print(\n","    \" This image most likely belongs to {} with a {:.2f} percent confidence.\"\n","    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",")\n","\n"],"metadata":{"id":"WWN9tJwr9C28"},"execution_count":null,"outputs":[]}]}